{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJWZibHLd9SJ"
   },
   "source": [
    "# Note 3/16/2019\n",
    "\n",
    "Accuracies based on various parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMVuL8J1d9SO"
   },
   "source": [
    "In this experiment, we are going to test the synthetic \"MNIST\" dataset, which is (very much) not linearly seperable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "omOoG9CCenpk",
    "outputId": "c980849c-67ef-477f-c536-b841719b7644"
   },
   "outputs": [],
   "source": [
    " \n",
    "# import os\n",
    "# import shutil\n",
    "# if \"README.md\" in os.listdir():\n",
    "#   print(\"The files are already in the folder\")\n",
    "\n",
    "    \n",
    "# else:\n",
    "#   !git clone https://github.com/wonjunee/mnist_gmu.git\n",
    "#   for i in (os.listdir('./mnist_gmu')):\n",
    "#     shutil.move(\"./mnist_gmu/{}\".format(i), \".\")\n",
    "\n",
    "#   for i in (os.listdir('.')):\n",
    "#     print(i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "s2gZx4I9d9SP",
    "outputId": "9eb8de58-07ad-4a00-ac75-ee22afbd3134"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ HELPER   FUNCTIONS IMPORTED ------\n",
      "------ TRAINING FUNCTIONS IMPORTED ------\n",
      "------ TEST     FUNCTIONS IMPORTED ------\n",
      "Function is ready\n"
     ]
    }
   ],
   "source": [
    "from model_20190302 import *\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "random.seed(702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hGVLMhN_d9SW"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# with tf.device('/device:gpu:0'):\n",
    "#     a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "#     b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "#     c = tf.matmul(a, b)\n",
    "\n",
    "# with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "#     print (sess.run(c))\n",
    "    \n",
    "# print(\"GPU is being used!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCLykIurd9SZ"
   },
   "source": [
    "# Bringing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "BQo7Ft8kd9Sb",
    "outputId": "f00c9836-02b7-446d-a6ab-6f92950855b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:From /home/fred/Dropbox/WonjunCode/mnist_gmu/helper/generate_data_mnist.py:15: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "Taking 100 per digit for train data\n",
      "y train one hot encoding: (1000, 10)\n",
      "y test one hot encoding: (10000, 10)\n",
      "\n",
      "Training Set:   (1000, 32, 32, 1)\n",
      "Test Set:       (10000, 32, 32, 1)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from helper.generate_data_mnist import *\n",
    "\n",
    "SIZE = 100\n",
    "reduced = True\n",
    "padding = True\n",
    "# Generate the data\n",
    "X_train, X_test, y_train, y_test, y_train_one_hot, y_test_one_hot = mnist_generate_data(reduced=reduced, train_size = SIZE, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSfIIFLmd9Sg"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FGH2nUbd9Sh"
   },
   "source": [
    "Shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "NmHYeMxKd9Sj",
    "outputId": "e24c1248-5723-48fc-d997-4e3e4ee5a5fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nddbCYZD09QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd665a109b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1000, 32, 32, 1)\n",
      "y_train: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "plt.hist(y_train, rwidth=0.85)\n",
    "plt.show()\n",
    "\n",
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"y_train:\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zk0wN2F5v_9w"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QQrXh65bd9Ss"
   },
   "outputs": [],
   "source": [
    "# learning rate\n",
    "rate = 0.001\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# make sure to change this parameter!!!!!\n",
    "filename = \"without-batch-full-size-20190316\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiht75pHd9Sq"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BY85ytxhd9Sw"
   },
   "outputs": [],
   "source": [
    "def evaluate(X_data, y_data):\n",
    "    \n",
    "    num_examples = len(X_data)\n",
    "    sess = tf.get_default_session()\n",
    "    \n",
    "    accuracy = sess.run([accuracy_operation,correct_prediction,logits,fc4,fc6], feed_dict={x: X_data, y: y_data})\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3250
    },
    "colab_type": "code",
    "id": "7d4lfR5id9Sz",
    "outputId": "4fd2c04f-4461-4611-a34e-7c3d9438d014",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-a55fae69b434>:22: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "# Matrix sizes for svm training\n",
    "mat_type_list = [\"2\", \"4\", \"6\"]\n",
    "\n",
    "tf_only  = []\n",
    "tf_svm2  = []\n",
    "tf_svm4  = []\n",
    "tf_svm6  = []\n",
    "    \n",
    "# initialize x axis for plot\n",
    "epochs_ranges = []\n",
    "\n",
    "accuracy_svc_linear = {}\n",
    "\n",
    "for mat in mat_type_list:\n",
    "    accuracy_svc_linear[mat] = []\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, X_train.shape[1],X_train.shape[2],X_train.shape[3]), \"x\")\n",
    "y = tf.placeholder(tf.int32, (None, 10), \"y\")\n",
    "\n",
    "logits, fc4, fc6 = pipeline(x)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        output = sess.run([training_operation, logits, fc4, fc6], feed_dict={x: X_train, y: y_train_one_hot})\n",
    "\n",
    "        if i % 2 == 0:\n",
    "\n",
    "            print(\"\\nEPOCHS:\", i)\n",
    "            Amat2,Amat4,Amat6 = output[1:]\n",
    "\n",
    "            epochs_ranges.append(i)\n",
    "\n",
    "            print(\"\\nTesting...\")\n",
    "            test_accuracy,prediction_tf,Amat2_test,Amat4_test,Amat6_test = evaluate(X_test, y_test_one_hot)\n",
    "\n",
    "            print(\"\\nTest Accuracy = {:.3f}\".format(test_accuracy))\n",
    "            \n",
    "            \n",
    "            # Appending tensorflow accuracies to the tf_only\n",
    "            tf_only.append(test_accuracy)\n",
    "\n",
    "            '''\n",
    "\n",
    "            in this model, there is no test data.\n",
    "            it is only using train data and evaluate on the train data.\n",
    "            so no need to worry about dividing into two sets\n",
    "\n",
    "            in the next for loop, I used the term train and test but\n",
    "            i just copied them from CIFAR10-tf-smaller.ipynb and didn't change the words.\n",
    "\n",
    "            '''\n",
    "\n",
    "            print(\"\\nTesting with SVM\")\n",
    "            for train_mat_type in mat_type_list: # only 6 and 16\n",
    "\n",
    "                if train_mat_type == \"2\":\n",
    "                    train_matrix = Amat2.copy()\n",
    "                    test_matrix  = Amat2_test.copy()\n",
    "                elif train_mat_type == \"4\":\n",
    "                    train_matrix = Amat4.copy()\n",
    "                    test_matrix  = Amat4_test.copy()\n",
    "                elif train_mat_type == \"6\":\n",
    "                    train_matrix = Amat6.copy()\n",
    "                    test_matrix  = Amat6_test.copy()                   \n",
    "\n",
    "                # With linear kernel\n",
    "                svc = SVC(kernel='linear')\n",
    "                svc.fit(train_matrix, y_train)\n",
    "                \n",
    "                print(\"Y_train:\",y_train.shape)\n",
    "                print(\"Y_train:\",y_test.shape)\n",
    "\n",
    "                prediction = svc.predict(test_matrix)\n",
    "                \n",
    "                print(\"prediction:\",prediction.shape)\n",
    "                \n",
    "                svc_linear_accuracy = np.sum(prediction==y_test.ravel())/len(prediction)\n",
    "\n",
    "                print('\\n train_mat_type: {}, Accuracy by SVC (linear): {}'.format(train_mat_type, svc_linear_accuracy))\n",
    "\n",
    "                accuracy_svc_linear[train_mat_type].append(svc_linear_accuracy)\n",
    "\n",
    "                # append accuracy to svm_only#\n",
    "                if train_mat_type == \"2\":\n",
    "                    tf_svm2.append(svc_linear_accuracy)\n",
    "                elif train_mat_type == \"4\":\n",
    "                    tf_svm4.append(svc_linear_accuracy)\n",
    "                elif train_mat_type == \"6\":\n",
    "                    tf_svm6.append(svc_linear_accuracy)\n",
    "\n",
    "    for train_mat_type in mat_type_list:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(epochs_ranges, accuracy_tf, 'o', label=\"TF\")\n",
    "        plt.plot(epochs_ranges, accuracy_svc_linear[train_mat_type], 'o',label=\"SVC (linear)\")\n",
    "\n",
    "        a = np.argmax(accuracy_tf)\n",
    "        plt.annotate(accuracy_tf[a], (epochs_ranges[a], accuracy_tf[a]))\n",
    "\n",
    "        a = np.argmax(accuracy_svc_linear[train_mat_type])\n",
    "        plt.annotate(accuracy_svc_linear[train_mat_type][a], (epochs_ranges[a], accuracy_svc_linear[train_mat_type][a]))\n",
    "\n",
    "        plt.legend()\n",
    "        title  = \"MNIST TF vs. SVC (linear) matrix size {}.png\".format(train_mat_type)\n",
    "        title1 = title\n",
    "        \n",
    "\n",
    "        plt.title(title1)\n",
    "        plt.grid()\n",
    "        plt.savefig(title)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "pickle.dump({\"tf_only\":tf_only, \"tf_svm2\":tf_svm2, \"tf_svm4\":tf_svm4, \"tf_svm6\":tf_svm6}, open(\"{}.p\".format(filename)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "20190302-MNIST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
