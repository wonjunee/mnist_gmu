{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJWZibHLd9SJ"
   },
   "source": [
    "# Note 3/2/2019\n",
    "\n",
    "Accuracies based on various parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMVuL8J1d9SO"
   },
   "source": [
    "In this experiment, we are going to test the synthetic \"MNIST\" dataset, which is (very much) not linearly seperable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "omOoG9CCenpk",
    "outputId": "a041a3b4-a2f7-4238-bd10-f952916a411a"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/wonjunee/mnist_gmu.git\n",
    "\n",
    "\n",
    "  \n",
    "# import os\n",
    "# import shutil\n",
    "# for i in (os.listdir('./mnist_gmu')):\n",
    "#   shutil.move(\"./mnist_gmu/{}\".format(i), \".\")\n",
    "  \n",
    "# for i in (os.listdir('.')):\n",
    "#   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "s2gZx4I9d9SP",
    "outputId": "c9a86a65-3d3d-4b83-dae9-05d6ad4dbaa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ HELPER   FUNCTIONS IMPORTED ------\n",
      "------ TRAINING FUNCTIONS IMPORTED ------\n",
      "------ TEST     FUNCTIONS IMPORTED ------\n",
      "Function is ready\n"
     ]
    }
   ],
   "source": [
    "from model_20190302 import *\n",
    "\n",
    "import sys\n",
    "import random\n",
    "\n",
    "random.seed(702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hGVLMhN_d9SW"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# with tf.device('/gpu:0'):\n",
    "#     a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "#     b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "#     c = tf.matmul(a, b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     print (sess.run(c))\n",
    "    \n",
    "# print(\"GPU is being used!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCLykIurd9SZ"
   },
   "source": [
    "# Bringing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "BQo7Ft8kd9Sb",
    "outputId": "1eadc89f-4120-44fe-9662-9bff896ecf28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:From /home/fred/Dropbox/WonjunCode/mnist_gmu/helper/generate_data_mnist.py:15: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/fred/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "Taking 100 per digit for train data\n",
      "y train one hot encoding: (55000, 10)\n",
      "y test one hot encoding: (10000, 10)\n",
      "\n",
      "Training Set:   (55000, 32, 32, 1)\n",
      "Test Set:       (10000, 32, 32, 1)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from helper.generate_data_mnist import *\n",
    "\n",
    "SIZE = 100\n",
    "reduced = True\n",
    "padding = True\n",
    "# Generate the data\n",
    "X_train, X_test, y_train, y_test, y_train_one_hot, y_test_one_hot = mnist_generate_data(reduced=reduced, train_size = SIZE, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSfIIFLmd9Sg"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FGH2nUbd9Sh"
   },
   "source": [
    "Shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "NmHYeMxKd9Sj",
    "outputId": "79d8e704-4fe3-4e61-9672-6b6803d9356b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabc7691dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (55000, 32, 32, 1)\n",
      "y_train: (55000, 1)\n"
     ]
    }
   ],
   "source": [
    "plt.hist(y_train, rwidth=0.85)\n",
    "plt.show()\n",
    "\n",
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"y_train:\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiht75pHd9Sq"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QQrXh65bd9Ss"
   },
   "outputs": [],
   "source": [
    "# learning rate\n",
    "rate = 0.001\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# make sure to change this parameter!!!!!\n",
    "filename_index = 0\n",
    "date = 20190302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BY85ytxhd9Sw"
   },
   "outputs": [],
   "source": [
    "def evaluate(X_data, y_data):\n",
    "    \n",
    "    num_examples = len(X_data)\n",
    "    sess = tf.get_default_session()\n",
    "    \n",
    "    accuracy = sess.run([accuracy_operation,correct_prediction,logits,fc4,fc6], feed_dict={x: X_data, y: y_data})\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8928
    },
    "colab_type": "code",
    "id": "7d4lfR5id9Sz",
    "outputId": "03d9b302-bcb3-4151-fdc5-45acea5b5cb0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-9c8ec090c814>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "# Matrix sizes for svm training\n",
    "mat_type_list = [\"2\", \"4\", \"6\"]\n",
    "\n",
    "tf_only  = []\n",
    "tf_svm2  = []\n",
    "tf_svm4  = []\n",
    "tf_svm6  = []\n",
    "\n",
    "# for D in D_list: # eventual dimension of noisy data\n",
    "#     for N in N_list: # number of data points\n",
    "#         svm_only[\"{}-{}\".format(D,N)] = []\n",
    "#         tf_only[\"{}-{}\".format(D,N)] = []        \n",
    "#         tf_svm2[\"{}-{}\".format(D,N)] = []\n",
    "#         tf_svm4[\"{}-{}\".format(D,N)] = []\n",
    "#         tf_svm6[\"{}-{}\".format(D,N)] = []\n",
    "#         tf_svm16[\"{}-{}\".format(D,N)] = []\n",
    "#         tf_svm64[\"{}-{}\".format(D,N)] = []\n",
    "\n",
    "    \n",
    "# initialize x axis for plot\n",
    "epochs_ranges = []\n",
    "\n",
    "accuracy_tf  = []\n",
    "\n",
    "accuracy_svc_linear = {}\n",
    "\n",
    "for mat in mat_type_list:\n",
    "    accuracy_svc_linear[mat] = []\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, X_train.shape[1],X_train.shape[2],X_train.shape[3]), \"x\")\n",
    "y = tf.placeholder(tf.int32, (None, 10), \"y\")\n",
    "\n",
    "logits, fc4, fc6 = pipeline(x)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        output = sess.run([training_operation, logits, fc4, fc6], feed_dict={x: X_train, y: y_train_one_hot})\n",
    "\n",
    "#         if i % 200 == 0 and i > 5000:\n",
    "        if True:\n",
    "\n",
    "            print(\"\\nEPOCHS:\", i)\n",
    "            Amat2,Amat4,Amat6 = output[1:]\n",
    "\n",
    "            epochs_ranges.append(i)\n",
    "\n",
    "            print(\"\\nTesting...\")\n",
    "            test_accuracy,prediction_tf,Amat2_test,Amat4_test,Amat6_test = evaluate(X_test, y_test_one_hot)\n",
    "\n",
    "            print(\"\\nTest Accuracy = {:.3f}\".format(test_accuracy))\n",
    "            \n",
    "            tf_only.append(test_accuracy)\n",
    "\n",
    "            accuracy_tf.append(test_accuracy)\n",
    "\n",
    "            '''\n",
    "\n",
    "            in this model, there is no test data.\n",
    "            it is only using train data and evaluate on the train data.\n",
    "            so no need to worry about dividing into two sets\n",
    "\n",
    "            in the next for loop, I used the term train and test but\n",
    "            i just copied them from CIFAR10-tf-smaller.ipynb and didn't change the words.\n",
    "\n",
    "            '''\n",
    "\n",
    "            for train_mat_type in mat_type_list: # only 6 and 16\n",
    "\n",
    "                if train_mat_type == \"2\":\n",
    "                    train_matrix = Amat2.copy()\n",
    "                    test_matrix  = Amat2_test.copy()\n",
    "                elif train_mat_type == \"4\":\n",
    "                    train_matrix = Amat4.copy()\n",
    "                    test_matrix  = Amat4_test.copy()\n",
    "                elif train_mat_type == \"6\":\n",
    "                    train_matrix = Amat6.copy()\n",
    "                    test_matrix  = Amat6_test.copy()                   \n",
    "\n",
    "                # With linear kernel\n",
    "                svc = SVC(kernel='linear')\n",
    "                svc.fit(train_matrix, y_train)\n",
    "                \n",
    "                print(\"Y_train:\",y_train.shape)\n",
    "                print(\"Y_train:\",y_test.shape)\n",
    "\n",
    "                prediction = svc.predict(test_matrix)\n",
    "                \n",
    "                print(\"prediction:\",prediction.shape)\n",
    "                \n",
    "                svc_linear_accuracy = np.sum(prediction==y_test.ravel())/len(prediction)\n",
    "\n",
    "                print('\\n train_mat_type: {}, Accuracy by SVC (linear): {}'.format(train_mat_type, svc_linear_accuracy))\n",
    "\n",
    "                accuracy_svc_linear[train_mat_type].append(svc_linear_accuracy)\n",
    "\n",
    "                # append accuracy to svm_only#\n",
    "                if train_mat_type == \"2\":\n",
    "                    tf_svm2.append(svc_linear_accuracy)\n",
    "                elif train_mat_type == \"4\":\n",
    "                    tf_svm4.append(svc_linear_accuracy)\n",
    "                elif train_mat_type == \"6\":\n",
    "                    tf_svm6.append(svc_linear_accuracy)\n",
    "\n",
    "    for train_mat_type in mat_type_list:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(epochs_ranges, accuracy_tf, 'o', label=\"TF\")\n",
    "        plt.plot(epochs_ranges, accuracy_svc_linear[train_mat_type], 'o',label=\"SVC (linear)\")\n",
    "\n",
    "        a = np.argmax(accuracy_tf)\n",
    "        plt.annotate(accuracy_tf[a], (epochs_ranges[a], accuracy_tf[a]))\n",
    "\n",
    "        a = np.argmax(accuracy_svc_linear[train_mat_type])\n",
    "        plt.annotate(accuracy_svc_linear[train_mat_type][a], (epochs_ranges[a], accuracy_svc_linear[train_mat_type][a]))\n",
    "\n",
    "        plt.legend()\n",
    "        title  = \"MNIST TF vs. SVC (linear) matrix size {}.png\".format(train_mat_type)\n",
    "        title1 = title\n",
    "        \n",
    "\n",
    "        plt.title(title1)\n",
    "        plt.grid()\n",
    "        plt.savefig(title)\n",
    "\n",
    "        plt.show()\n",
    "                \n",
    "# np.savez(\"{}-multiple-runs-{}.npz\".format(date,filename_index), \\\n",
    "#                         svm_only = svm_only, \\\n",
    "#                         tf_only  = tf_only, \\\n",
    "#                         tf_svm2  = tf_svm2, \\\n",
    "#                         tf_svm4  = tf_svm4, \\\n",
    "#                         tf_svm6  = tf_svm6)\n",
    "\n",
    "import pickle\n",
    "pickle.dump({\"tf_only\":tf_only, \"tf_svm2\":tf_svm2, \"tf_svm4\":tf_svm4, \"tf_svm6\":tf_svm6}, open(\"{}-{}.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Bcy6ZsPd9S3",
    "outputId": "719301cd-3ca0-46bf-af66-f4c9b8c69aad"
   },
   "outputs": [],
   "source": [
    "npz_data = np.load(\"{}-multiple-runs-{}.npz\".format(date,filename_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mp6D4sNPd9S_"
   },
   "outputs": [],
   "source": [
    "keys = npz_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lsHKZfxmd9TB"
   },
   "outputs": [],
   "source": [
    "for i in keys:\n",
    "    print(i)\n",
    "    print(npz_data[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "A2zkPzMXd9TE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "20190302-MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
